{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:51.875418Z",
     "start_time": "2024-04-22T21:44:46.640602600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import av\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoProcessor, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:51.881828Z",
     "start_time": "2024-04-22T21:44:51.879828100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "root_dir = 'UCF-101/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:51.912626700Z",
     "start_time": "2024-04-22T21:44:51.883826600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load pretrained transformer model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "XCLIPModel(\n  (text_model): XCLIPTextTransformer(\n    (embeddings): XCLIPTextEmbeddings(\n      (token_embedding): Embedding(49408, 512)\n      (position_embedding): Embedding(77, 512)\n    )\n    (encoder): XCLIPEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x XCLIPEncoderLayer(\n          (self_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (mlp): XCLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (vision_model): XCLIPVisionTransformer(\n    (embeddings): XCLIPVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n      (position_embedding): Embedding(50, 768)\n    )\n    (pre_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (encoder): XCLIPVisionEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x XCLIPVisionEncoderLayer(\n          (message_fc): Linear(in_features=768, out_features=768, bias=True)\n          (message_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (message_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (self_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): XCLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n  (prompts_visual_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (mit): XCLIPMultiframeIntegrationTransformer(\n    (encoder): XCLIPEncoder(\n      (layers): ModuleList(\n        (0): XCLIPEncoderLayer(\n          (self_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (mlp): XCLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (prompts_generator): XCLIPPromptGenerator(\n    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (decoder): ModuleList(\n      (0-1): 2 x PromptGeneratorLayer(\n        (cross_attn): XCLIPCrossAttention(\n          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): QuickGELUActivation()\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"microsoft/xclip-base-patch32\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/xclip-base-patch32\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:55.542429500Z",
     "start_time": "2024-04-22T21:44:51.913628800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0          label   youtube_id  time_start  time_end  split  \\\n0       23948  belly dancing  uhX8rmHFLaY         116       126  train   \n1       23843  belly dancing  -q0Wpf0WThk         317       327  train   \n2       24142  belly dancing  P9mOEmlCEXY          62        72  train   \n3       23467  belly dancing  mm5S2ftbb-k          32        42  train   \n4       23982  belly dancing  TCbfIBb87hQ         134       144  train   \n\n                                 video_path  \n0  data/kinetics_700/videos/uhX8rmHFLaY.mp4  \n1  data/kinetics_700/videos/-q0Wpf0WThk.mp4  \n2  data/kinetics_700/videos/P9mOEmlCEXY.mp4  \n3  data/kinetics_700/videos/mm5S2ftbb-k.mp4  \n4  data/kinetics_700/videos/TCbfIBb87hQ.mp4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>label</th>\n      <th>youtube_id</th>\n      <th>time_start</th>\n      <th>time_end</th>\n      <th>split</th>\n      <th>video_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23948</td>\n      <td>belly dancing</td>\n      <td>uhX8rmHFLaY</td>\n      <td>116</td>\n      <td>126</td>\n      <td>train</td>\n      <td>data/kinetics_700/videos/uhX8rmHFLaY.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23843</td>\n      <td>belly dancing</td>\n      <td>-q0Wpf0WThk</td>\n      <td>317</td>\n      <td>327</td>\n      <td>train</td>\n      <td>data/kinetics_700/videos/-q0Wpf0WThk.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24142</td>\n      <td>belly dancing</td>\n      <td>P9mOEmlCEXY</td>\n      <td>62</td>\n      <td>72</td>\n      <td>train</td>\n      <td>data/kinetics_700/videos/P9mOEmlCEXY.mp4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23467</td>\n      <td>belly dancing</td>\n      <td>mm5S2ftbb-k</td>\n      <td>32</td>\n      <td>42</td>\n      <td>train</td>\n      <td>data/kinetics_700/videos/mm5S2ftbb-k.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23982</td>\n      <td>belly dancing</td>\n      <td>TCbfIBb87hQ</td>\n      <td>134</td>\n      <td>144</td>\n      <td>train</td>\n      <td>data/kinetics_700/videos/TCbfIBb87hQ.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\kinetics_700\\dancing.csv\")\n",
    "df[\"video_path\"] =  \"data/kinetics_700/videos/\" + df[\"youtube_id\"] + \".mp4\"\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:55.604744200Z",
     "start_time": "2024-04-22T21:44:55.543421600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 3000\n",
      "data/kinetics_700/videos/PL3ex5IAQNw.mp4\n",
      "data/kinetics_700/videos/NJAIp24I9oQ.mp4\n",
      "data/kinetics_700/videos/_ubj_hjLdVc.mp4\n",
      "data/kinetics_700/videos/iQuTmRkOuIo.mp4\n",
      "data/kinetics_700/videos/Y_rtxFTnyWI.mp4\n",
      "data/kinetics_700/videos/cNvTm72aGcM.mp4\n",
      "data/kinetics_700/videos/YUJVnjzPZxI.mp4\n",
      "data/kinetics_700/videos/ooN3OOKuAjY.mp4\n",
      "data/kinetics_700/videos/sbvNyPubcFM.mp4\n",
      "data/kinetics_700/videos/g3E8Cjog6-k.mp4\n",
      "data/kinetics_700/videos/iJ5KAamDDP8.mp4\n",
      "data/kinetics_700/videos/kuJO1VapxuQ.mp4\n",
      "data/kinetics_700/videos/88jZP1BLXEs.mp4\n",
      "data/kinetics_700/videos/yEEDk2CMOTI.mp4\n",
      "data/kinetics_700/videos/zt7XHcgHdEc.mp4\n",
      "data/kinetics_700/videos/Sw4Ggaya3ys.mp4\n",
      "data/kinetics_700/videos/s5GJdHQL_Wc.mp4\n",
      "data/kinetics_700/videos/N4UtAez9QVE.mp4\n",
      "data/kinetics_700/videos/NLhhoE7es8g.mp4\n",
      "data/kinetics_700/videos/uvoBn-8AxHI.mp4\n",
      "data/kinetics_700/videos/xvNiI_ScL1I.mp4\n",
      "data/kinetics_700/videos/eU7aTQHNTdw.mp4\n",
      "data/kinetics_700/videos/yJlFSAsm55A.mp4\n",
      "data/kinetics_700/videos/ros4Qypsgx8.mp4\n",
      "data/kinetics_700/videos/WfReigRwWL8.mp4\n",
      "data/kinetics_700/videos/bY0k_4SQx0c.mp4\n",
      "data/kinetics_700/videos/Os66zjMaxyM.mp4\n",
      "data/kinetics_700/videos/tkU_8wbm5PI.mp4\n",
      "data/kinetics_700/videos/RB2LsZrsp7M.mp4\n",
      "data/kinetics_700/videos/900sTBL7rUI.mp4\n",
      "data/kinetics_700/videos/Fd8A6KMum_U.mp4\n",
      "data/kinetics_700/videos/eBswIBFiyBs.mp4\n",
      "data/kinetics_700/videos/gE3P4lxAgt4.mp4\n",
      "data/kinetics_700/videos/gFHv0ahXTGQ.mp4\n",
      "data/kinetics_700/videos/XtRSuv2pD5A.mp4\n",
      "data/kinetics_700/videos/9AkuTMwhHQE.mp4\n",
      "data/kinetics_700/videos/0f1vKMit9uw.mp4\n",
      "data/kinetics_700/videos/p4D01Sj7Mjk.mp4\n",
      "data/kinetics_700/videos/IPLpD_PGMHk.mp4\n",
      "data/kinetics_700/videos/O0EY3HcAKfU.mp4\n",
      "data/kinetics_700/videos/4XVx7PJsKv4.mp4\n",
      "data/kinetics_700/videos/bArxc3nChSU.mp4\n",
      "data/kinetics_700/videos/6adKBbLYH1g.mp4\n",
      "data/kinetics_700/videos/vE5pXxbm9n8.mp4\n",
      "data/kinetics_700/videos/7daoZfaJC4I.mp4\n",
      "data/kinetics_700/videos/0hpxpFsDuSA.mp4\n",
      "data/kinetics_700/videos/dqv-2j_1K-w.mp4\n",
      "data/kinetics_700/videos/EfTkNx6ckJs.mp4\n",
      "data/kinetics_700/videos/-8snoM0IJ68.mp4\n",
      "data/kinetics_700/videos/SdQVS19X7f8.mp4\n",
      "data/kinetics_700/videos/lX_YJ4SFt4c.mp4\n",
      "data/kinetics_700/videos/h8_JHpUVTtE.mp4\n",
      "data/kinetics_700/videos/raFHfveSxPc.mp4\n",
      "data/kinetics_700/videos/g8WQflTwDWw.mp4\n",
      "data/kinetics_700/videos/hR31BlhDrew.mp4\n",
      "data/kinetics_700/videos/nBqnC-pSdYk.mp4\n",
      "data/kinetics_700/videos/kcLsYzNQNwI.mp4\n",
      "data/kinetics_700/videos/rhxsbI7BgzA.mp4\n",
      "data/kinetics_700/videos/SDDdj2dhxeE.mp4\n",
      "data/kinetics_700/videos/-A6-ubbxy3w.mp4\n",
      "data/kinetics_700/videos/gwAHj75vebI.mp4\n",
      "data/kinetics_700/videos/c-MtXbJmtdw.mp4\n",
      "data/kinetics_700/videos/YaxGSSdeio0.mp4\n",
      "data/kinetics_700/videos/7EfWZ6FSxBo.mp4\n",
      "data/kinetics_700/videos/JFraNvErZJ0.mp4\n",
      "data/kinetics_700/videos/4BJ_2Y0M9Tw.mp4\n",
      "data/kinetics_700/videos/fNkk4e2OwWo.mp4\n",
      "data/kinetics_700/videos/nD7eYr57bD4.mp4\n",
      "data/kinetics_700/videos/EE0O2NzrfOI.mp4\n",
      "data/kinetics_700/videos/0EI804x_Qe0.mp4\n",
      "data/kinetics_700/videos/UNicpaBHsoA.mp4\n",
      "data/kinetics_700/videos/aLbTp9PZgbw.mp4\n",
      "data/kinetics_700/videos/rQiyz36aLDk.mp4\n",
      "data/kinetics_700/videos/vxpCm6h9rD8.mp4\n",
      "data/kinetics_700/videos/n3MVGqLbEtk.mp4\n",
      "data/kinetics_700/videos/T5HdKXg1d1o.mp4\n",
      "data/kinetics_700/videos/p_ebLuGOYIs.mp4\n",
      "data/kinetics_700/videos/PnpzUKyzWmo.mp4\n",
      "data/kinetics_700/videos/aJH19JtxnF0.mp4\n",
      "data/kinetics_700/videos/bBJ535mR6xU.mp4\n",
      "data/kinetics_700/videos/YlQFXQ4aNfs.mp4\n",
      "data/kinetics_700/videos/_fBXuqLns00.mp4\n",
      "data/kinetics_700/videos/h21snM6XvLY.mp4\n",
      "data/kinetics_700/videos/zmbSLm652C0.mp4\n",
      "data/kinetics_700/videos/qb3QrFZJLIE.mp4\n",
      "data/kinetics_700/videos/Aq7IVzsKXjQ.mp4\n",
      "data/kinetics_700/videos/0wwzMnMQTV0.mp4\n",
      "data/kinetics_700/videos/buUfv9eu_3c.mp4\n",
      "data/kinetics_700/videos/r3JDPpjD8l8.mp4\n",
      "data/kinetics_700/videos/N0Ph13LsR5A.mp4\n",
      "data/kinetics_700/videos/-B3ugc7t7aU.mp4\n",
      "data/kinetics_700/videos/T2_AKLeEVj8.mp4\n",
      "data/kinetics_700/videos/PzKw_sdJzjQ.mp4\n",
      "data/kinetics_700/videos/CLXwtveP3S8.mp4\n",
      "data/kinetics_700/videos/_ZSbbAW7NwQ.mp4\n",
      "data/kinetics_700/videos/8WBa7tAkc-k.mp4\n",
      "data/kinetics_700/videos/QpW0_0hYLYE.mp4\n",
      "data/kinetics_700/videos/65WRMPboy3s.mp4\n",
      "data/kinetics_700/videos/YyHEOHtyqBY.mp4\n",
      "data/kinetics_700/videos/i2CO0BZOeoA.mp4\n",
      "data/kinetics_700/videos/Nd1n5qY7pCQ.mp4\n",
      "data/kinetics_700/videos/vZRQGxeSTjE.mp4\n",
      "data/kinetics_700/videos/TOjVChL2RLk.mp4\n",
      "data/kinetics_700/videos/LrKjWFA1lAo.mp4\n",
      "data/kinetics_700/videos/Q7nF0nwnZs0.mp4\n",
      "data/kinetics_700/videos/I_qT2xDDDac.mp4\n",
      "data/kinetics_700/videos/W_PNiyYgoOM.mp4\n",
      "data/kinetics_700/videos/c1hHxrhEeZk.mp4\n",
      "data/kinetics_700/videos/LTbZV-VUbps.mp4\n",
      "data/kinetics_700/videos/Ntv7xMwUetA.mp4\n",
      "data/kinetics_700/videos/bxMp2ZZOByo.mp4\n",
      "data/kinetics_700/videos/YrVrl4WnJZA.mp4\n",
      "data/kinetics_700/videos/8EOP98US9Ks.mp4\n",
      "data/kinetics_700/videos/hOKljMC66tE.mp4\n",
      "data/kinetics_700/videos/j3D5mdhLQsw.mp4\n",
      "data/kinetics_700/videos/74elZg5xFLU.mp4\n",
      "data/kinetics_700/videos/JmSdDUoMG20.mp4\n",
      "data/kinetics_700/videos/V-fWxn6DHtc.mp4\n",
      "data/kinetics_700/videos/dwBXEjNfDb4.mp4\n",
      "data/kinetics_700/videos/3IWHE7_WFDE.mp4\n",
      "data/kinetics_700/videos/SAnv6LOPH1c.mp4\n",
      "data/kinetics_700/videos/dSyiGI1Zmiw.mp4\n",
      "data/kinetics_700/videos/X_TQd6vTnkw.mp4\n",
      "data/kinetics_700/videos/natnD1jofBg.mp4\n",
      "data/kinetics_700/videos/KWrOqybn9ts.mp4\n",
      "data/kinetics_700/videos/EkH-oJDrhNg.mp4\n",
      "data/kinetics_700/videos/TBfJ0M7Qah4.mp4\n",
      "data/kinetics_700/videos/UEua4xOuixI.mp4\n",
      "data/kinetics_700/videos/dBJiQEhe8m0.mp4\n",
      "data/kinetics_700/videos/mLlhy4a7yvY.mp4\n",
      "data/kinetics_700/videos/5mEP3BbXqjE.mp4\n",
      "data/kinetics_700/videos/MrygPovksSk.mp4\n",
      "data/kinetics_700/videos/PSi_FwEICxc.mp4\n",
      "data/kinetics_700/videos/OlhDxxPK_1Y.mp4\n",
      "data/kinetics_700/videos/9l19jzphV4M.mp4\n",
      "data/kinetics_700/videos/GNxzE3MleJk.mp4\n",
      "data/kinetics_700/videos/DXtjkRunpLg.mp4\n",
      "data/kinetics_700/videos/JyMuGe4-kSA.mp4\n",
      "data/kinetics_700/videos/EBakJFfju4A.mp4\n",
      "data/kinetics_700/videos/rT8V7tBn324.mp4\n",
      "data/kinetics_700/videos/Xmg1nWrz7nw.mp4\n",
      "data/kinetics_700/videos/TGbudmrQs3U.mp4\n",
      "data/kinetics_700/videos/jWMj26xY9O0.mp4\n",
      "data/kinetics_700/videos/e_V_W8ZZ0yw.mp4\n",
      "data/kinetics_700/videos/EaobS0zIleE.mp4\n",
      "data/kinetics_700/videos/fjdCtfe461M.mp4\n",
      "data/kinetics_700/videos/Ra_wdynM7Lk.mp4\n",
      "data/kinetics_700/videos/CSEwkXFRIZw.mp4\n",
      "data/kinetics_700/videos/wX9Q9QoiYgk.mp4\n",
      "data/kinetics_700/videos/kgHbV6kxZzI.mp4\n",
      "data/kinetics_700/videos/2WPzgG1-TF0.mp4\n",
      "data/kinetics_700/videos/yAHOI5tH7fs.mp4\n",
      "data/kinetics_700/videos/Mz1UPUVPQqI.mp4\n",
      "data/kinetics_700/videos/Z67v6arjAnM.mp4\n",
      "data/kinetics_700/videos/r_GxpS-8gYk.mp4\n",
      "data/kinetics_700/videos/PARhnPb-jN0.mp4\n",
      "data/kinetics_700/videos/NFeXT5H3bJk.mp4\n",
      "data/kinetics_700/videos/oaRmZ49KJDk.mp4\n",
      "data/kinetics_700/videos/IIQl0T_s1YY.mp4\n",
      "data/kinetics_700/videos/2rsZP151pKw.mp4\n",
      "data/kinetics_700/videos/vU7nssnIna4.mp4\n",
      "data/kinetics_700/videos/EMp1V1Bmf7w.mp4\n",
      "data/kinetics_700/videos/M6vUyIGCK-g.mp4\n",
      "data/kinetics_700/videos/XWvZ6BkBN3A.mp4\n",
      "data/kinetics_700/videos/Q_ByJbSAwAs.mp4\n",
      "data/kinetics_700/videos/Oiibk0gAR5I.mp4\n",
      "data/kinetics_700/videos/e4X5z8AQc3s.mp4\n",
      "data/kinetics_700/videos/q5U1upD0g9M.mp4\n",
      "data/kinetics_700/videos/fl56tjPytbY.mp4\n",
      "data/kinetics_700/videos/AQKWUxPHDRA.mp4\n",
      "data/kinetics_700/videos/B98ia97YxvI.mp4\n",
      "data/kinetics_700/videos/tr6b3ZLMKyc.mp4\n",
      "data/kinetics_700/videos/V4a2BagLVRY.mp4\n",
      "data/kinetics_700/videos/o6sQeK44b78.mp4\n",
      "data/kinetics_700/videos/rrqcZhNUVIU.mp4\n",
      "data/kinetics_700/videos/1HAhF8UZ9MA.mp4\n",
      "data/kinetics_700/videos/LzI3zrjX6K8.mp4\n",
      "data/kinetics_700/videos/o5oIWjZOvy4.mp4\n",
      "data/kinetics_700/videos/u6dLn-CfDCM.mp4\n",
      "data/kinetics_700/videos/PzbnishugVM.mp4\n",
      "data/kinetics_700/videos/TVr9VyysveI.mp4\n",
      "data/kinetics_700/videos/aKpL5RtYH-0.mp4\n",
      "data/kinetics_700/videos/NxiXJoF9HCo.mp4\n",
      "data/kinetics_700/videos/ezngImN3D5A.mp4\n",
      "data/kinetics_700/videos/1xgRad-jeI8.mp4\n",
      "data/kinetics_700/videos/4BALx-8ijz0.mp4\n",
      "data/kinetics_700/videos/7l4Ygt3qpTA.mp4\n",
      "data/kinetics_700/videos/vNpcPa0Z9Bo.mp4\n",
      "data/kinetics_700/videos/vW8zmnXPlKY.mp4\n",
      "data/kinetics_700/videos/s_b3x1uhmm0.mp4\n",
      "data/kinetics_700/videos/aif8bjP4jH0.mp4\n",
      "data/kinetics_700/videos/30yMANnkLQo.mp4\n",
      "data/kinetics_700/videos/JZmh9gGZYjw.mp4\n",
      "data/kinetics_700/videos/YaxI7l21s5U.mp4\n",
      "data/kinetics_700/videos/tbzrcupNcZc.mp4\n",
      "data/kinetics_700/videos/FbPUX8cWmeU.mp4\n",
      "data/kinetics_700/videos/rxcoW8MHBGY.mp4\n",
      "data/kinetics_700/videos/Ibw9n2Myrz0.mp4\n",
      "data/kinetics_700/videos/shuDmNDrckg.mp4\n",
      "data/kinetics_700/videos/aOUmIhOy9i0.mp4\n",
      "data/kinetics_700/videos/pkwJtXiGA3A.mp4\n",
      "data/kinetics_700/videos/sF2LLedArF4.mp4\n",
      "data/kinetics_700/videos/Vyk6jMZ95B0.mp4\n",
      "data/kinetics_700/videos/zhX-VZrEil0.mp4\n",
      "data/kinetics_700/videos/7LmsLfnAtTw.mp4\n",
      "data/kinetics_700/videos/1q78VQqIUbI.mp4\n",
      "data/kinetics_700/videos/rEEEREW02C8.mp4\n",
      "data/kinetics_700/videos/9bwQZd_DoxA.mp4\n",
      "data/kinetics_700/videos/91YXtNIv-So.mp4\n",
      "data/kinetics_700/videos/_32OaGSeb0Q.mp4\n",
      "data/kinetics_700/videos/ezkkKrk7-u4.mp4\n",
      "data/kinetics_700/videos/ah8c7LBkPhg.mp4\n",
      "data/kinetics_700/videos/X3Lg9bTMQHs.mp4\n",
      "data/kinetics_700/videos/bHuTRITD_Z0.mp4\n",
      "data/kinetics_700/videos/UqbPNmdiEQE.mp4\n",
      "data/kinetics_700/videos/BUZN0sJdZBI.mp4\n",
      "data/kinetics_700/videos/w3h9_-ECM-c.mp4\n",
      "data/kinetics_700/videos/f1zIumR21Vk.mp4\n",
      "data/kinetics_700/videos/lBzcKR5EzUs.mp4\n",
      "data/kinetics_700/videos/n1FEcgaF_Yc.mp4\n",
      "data/kinetics_700/videos/j_JWwHUKTlE.mp4\n",
      "data/kinetics_700/videos/Lq9BEVJObuw.mp4\n",
      "data/kinetics_700/videos/qteOBxcecdo.mp4\n",
      "data/kinetics_700/videos/1dhbh3JUe_o.mp4\n",
      "data/kinetics_700/videos/XeNcOGkbc50.mp4\n",
      "data/kinetics_700/videos/RUeBVXHf9HE.mp4\n",
      "data/kinetics_700/videos/e5wkSctRh6E.mp4\n",
      "data/kinetics_700/videos/0rhk4HYpN64.mp4\n",
      "data/kinetics_700/videos/ADNTLM6KMKo.mp4\n",
      "data/kinetics_700/videos/ioCPxUJgr1g.mp4\n",
      "data/kinetics_700/videos/AjlQzOpebcc.mp4\n",
      "data/kinetics_700/videos/0nATf03yGfY.mp4\n",
      "data/kinetics_700/videos/VhpSUzzbk8Y.mp4\n",
      "data/kinetics_700/videos/7pOnWjBVOk8.mp4\n",
      "data/kinetics_700/videos/8mm3AF75pmc.mp4\n",
      "data/kinetics_700/videos/E3v_QqzsvWE.mp4\n",
      "data/kinetics_700/videos/V4dWuT3XB7U.mp4\n",
      "data/kinetics_700/videos/u63r67bzKls.mp4\n",
      "data/kinetics_700/videos/Z6fCVegfxN8.mp4\n",
      "data/kinetics_700/videos/MJJ-dW-Qk-k.mp4\n",
      "data/kinetics_700/videos/E-1DPx6uCC8.mp4\n",
      "data/kinetics_700/videos/nSplr_TTsjQ.mp4\n",
      "data/kinetics_700/videos/7Pdcp3ahRZE.mp4\n",
      "data/kinetics_700/videos/f6wVxpn-pvA.mp4\n",
      "data/kinetics_700/videos/CTAfs8Q-5qQ.mp4\n",
      "data/kinetics_700/videos/0CApQWg8ViU.mp4\n",
      "data/kinetics_700/videos/2bTz86eGvCQ.mp4\n",
      "data/kinetics_700/videos/HM8uVUd10f4.mp4\n",
      "data/kinetics_700/videos/u3MVWyVRR8E.mp4\n",
      "data/kinetics_700/videos/IcUc9hg8qVI.mp4\n",
      "data/kinetics_700/videos/wp8IFo2MAhs.mp4\n",
      "data/kinetics_700/videos/rf2bcXgeN20.mp4\n",
      "data/kinetics_700/videos/yvE_qU4G4iw.mp4\n",
      "data/kinetics_700/videos/xHHLhgO94oE.mp4\n",
      "data/kinetics_700/videos/3Wel_i6WRDA.mp4\n",
      "data/kinetics_700/videos/bn0JYGVxyvg.mp4\n",
      "data/kinetics_700/videos/aLSZqZO3oMk.mp4\n",
      "data/kinetics_700/videos/CV89K-iTL_8.mp4\n",
      "data/kinetics_700/videos/wz8I8VOT9yM.mp4\n",
      "data/kinetics_700/videos/UdFXugWdS94.mp4\n",
      "data/kinetics_700/videos/z2jer5hWx1E.mp4\n",
      "data/kinetics_700/videos/Smp7h-SHt-Y.mp4\n",
      "data/kinetics_700/videos/76kYX5BRHgE.mp4\n",
      "data/kinetics_700/videos/PWEYGzI7gT8.mp4\n",
      "data/kinetics_700/videos/NJE3nR-ookY.mp4\n",
      "data/kinetics_700/videos/Ta9d3KV3b7s.mp4\n",
      "data/kinetics_700/videos/Eu0anJhSigY.mp4\n",
      "data/kinetics_700/videos/NrT68twfGIk.mp4\n",
      "data/kinetics_700/videos/aHdPch4H-dY.mp4\n",
      "data/kinetics_700/videos/qDiKelyUZJQ.mp4\n",
      "data/kinetics_700/videos/EdkoU8vZweI.mp4\n",
      "data/kinetics_700/videos/1QvF3Ep3VbY.mp4\n",
      "data/kinetics_700/videos/DqWTF_OLX_E.mp4\n",
      "data/kinetics_700/videos/PkfVHxYnYpg.mp4\n",
      "data/kinetics_700/videos/w6aMMgCiDNQ.mp4\n",
      "data/kinetics_700/videos/NzEAJ8x6-Fk.mp4\n",
      "data/kinetics_700/videos/JRJrVNBah-Q.mp4\n",
      "data/kinetics_700/videos/qi9G3bedKng.mp4\n",
      "data/kinetics_700/videos/3wlhpfRowJQ.mp4\n",
      "data/kinetics_700/videos/PfTLArcL3m8.mp4\n",
      "data/kinetics_700/videos/9U9wlqPshu8.mp4\n",
      "data/kinetics_700/videos/d2s1jZT8kJQ.mp4\n",
      "data/kinetics_700/videos/TaF6wPth3Ks.mp4\n",
      "data/kinetics_700/videos/xEpzW2OB2o0.mp4\n",
      "data/kinetics_700/videos/iJg7CJ08OLY.mp4\n",
      "data/kinetics_700/videos/CfE2PkGcmTY.mp4\n",
      "data/kinetics_700/videos/0ErBwoEUrjI.mp4\n",
      "data/kinetics_700/videos/tb9AyhPAK48.mp4\n",
      "data/kinetics_700/videos/eypk3vSZNOM.mp4\n",
      "data/kinetics_700/videos/rfcYohkeQj8.mp4\n",
      "data/kinetics_700/videos/lrOlZop7g_8.mp4\n",
      "data/kinetics_700/videos/31VwNtHjSdI.mp4\n",
      "data/kinetics_700/videos/cb5mnc05OYM.mp4\n",
      "data/kinetics_700/videos/a9nKJuji61A.mp4\n",
      "data/kinetics_700/videos/CFoChi8-7Ak.mp4\n",
      "data/kinetics_700/videos/mfgnSepPXdk.mp4\n",
      "data/kinetics_700/videos/QyPUP8EOE0Y.mp4\n",
      "data/kinetics_700/videos/NSMuqCmNkJY.mp4\n",
      "data/kinetics_700/videos/QFcVWsfOeMU.mp4\n",
      "data/kinetics_700/videos/o7JgZ9ayGtY.mp4\n",
      "data/kinetics_700/videos/jbTh5cginhw.mp4\n",
      "data/kinetics_700/videos/ArTHHG_98No.mp4\n",
      "data/kinetics_700/videos/1b1MbeNO7lg.mp4\n",
      "data/kinetics_700/videos/SOWPD8snKYA.mp4\n",
      "data/kinetics_700/videos/crzD18En--M.mp4\n",
      "data/kinetics_700/videos/_VhC5u6ndis.mp4\n",
      "data/kinetics_700/videos/CvQfLHlE-PA.mp4\n",
      "data/kinetics_700/videos/5zYbx4rHUyY.mp4\n",
      "data/kinetics_700/videos/AGtOZzNauUo.mp4\n",
      "data/kinetics_700/videos/pDLM-5PHliA.mp4\n",
      "data/kinetics_700/videos/dLVEqCqWwmc.mp4\n",
      "data/kinetics_700/videos/BN56cms2DFE.mp4\n",
      "data/kinetics_700/videos/I8QMtGSQhmA.mp4\n",
      "data/kinetics_700/videos/B36_N8AeMjc.mp4\n",
      "data/kinetics_700/videos/FyDuUqs30-4.mp4\n",
      "data/kinetics_700/videos/Uf3GCS9DIsE.mp4\n",
      "data/kinetics_700/videos/-ciVOQS2RHo.mp4\n",
      "data/kinetics_700/videos/ElSTJi6khgs.mp4\n",
      "data/kinetics_700/videos/sBLqY5Jii_I.mp4\n",
      "data/kinetics_700/videos/L8PnQzDgFNM.mp4\n",
      "data/kinetics_700/videos/NgfU4cX8oOg.mp4\n",
      "data/kinetics_700/videos/iOwVWPkYm_I.mp4\n",
      "data/kinetics_700/videos/nEIjKLCTD5w.mp4\n",
      "data/kinetics_700/videos/cgEyu3A8gA0.mp4\n",
      "data/kinetics_700/videos/NBFY5wr8diQ.mp4\n",
      "data/kinetics_700/videos/8qvgPlDrWsk.mp4\n",
      "data/kinetics_700/videos/7fU9Xx7n6xE.mp4\n",
      "data/kinetics_700/videos/NikFyUs7X58.mp4\n",
      "data/kinetics_700/videos/dtZwDqMYcs0.mp4\n",
      "data/kinetics_700/videos/8W_4z6aVbXw.mp4\n",
      "data/kinetics_700/videos/u41FO8eRv3E.mp4\n",
      "data/kinetics_700/videos/RCgKqI3w59E.mp4\n",
      "data/kinetics_700/videos/H7ZIqt72rao.mp4\n",
      "data/kinetics_700/videos/ErSXWdSP8mQ.mp4\n",
      "data/kinetics_700/videos/di8-ugh6q_w.mp4\n",
      "data/kinetics_700/videos/4jw4gK7m-rE.mp4\n",
      "data/kinetics_700/videos/HKWbc3O6jcQ.mp4\n",
      "data/kinetics_700/videos/MCLCpaNSFFc.mp4\n",
      "data/kinetics_700/videos/ib_hIMo2zMg.mp4\n",
      "data/kinetics_700/videos/y7bcuvpmz_s.mp4\n",
      "data/kinetics_700/videos/WSxj9cb85BE.mp4\n",
      "data/kinetics_700/videos/YlQhQEs-U9E.mp4\n",
      "data/kinetics_700/videos/pc4UwXXhsQM.mp4\n",
      "data/kinetics_700/videos/6ak1IED7SO4.mp4\n",
      "data/kinetics_700/videos/8YscXcbgf54.mp4\n",
      "data/kinetics_700/videos/SIm_TNWBrHg.mp4\n",
      "data/kinetics_700/videos/V6yFLsMd8jY.mp4\n",
      "data/kinetics_700/videos/FUCQwcSt2EY.mp4\n",
      "data/kinetics_700/videos/0926nXPz1gY.mp4\n",
      "data/kinetics_700/videos/9LPQS0C-v5s.mp4\n",
      "data/kinetics_700/videos/CX95p8YLJL4.mp4\n",
      "data/kinetics_700/videos/ZeQ2zwkrffM.mp4\n",
      "data/kinetics_700/videos/2MgdIxEXPjw.mp4\n",
      "data/kinetics_700/videos/JkXo2jz8PSo.mp4\n",
      "data/kinetics_700/videos/OEodiMsTGxE.mp4\n",
      "data/kinetics_700/videos/yHnY9GCjt5E.mp4\n",
      "data/kinetics_700/videos/w7iRS6FV7FE.mp4\n",
      "data/kinetics_700/videos/mY_-zsJODZw.mp4\n",
      "data/kinetics_700/videos/xWlbfS-hYuM.mp4\n",
      "data/kinetics_700/videos/_54lH029gxs.mp4\n",
      "data/kinetics_700/videos/J85Msdi9Kgk.mp4\n",
      "data/kinetics_700/videos/sAHpca09P0I.mp4\n",
      "data/kinetics_700/videos/pIFGfwQKeEE.mp4\n",
      "data/kinetics_700/videos/YQJfrb2k00k.mp4\n",
      "data/kinetics_700/videos/o8BiF4x2q-Q.mp4\n",
      "data/kinetics_700/videos/HFgIXxJyGmg.mp4\n",
      "data/kinetics_700/videos/WFBA0RxdDqw.mp4\n",
      "data/kinetics_700/videos/ZKFhlncm_ec.mp4\n",
      "data/kinetics_700/videos/X-P_jbIVe6s.mp4\n",
      "data/kinetics_700/videos/BIVXHbCZBfg.mp4\n",
      "data/kinetics_700/videos/fXKQENVpr8c.mp4\n",
      "data/kinetics_700/videos/JKkSjQumtmA.mp4\n",
      "data/kinetics_700/videos/TftKt5yM8bo.mp4\n",
      "data/kinetics_700/videos/bGHtr46U8Pc.mp4\n",
      "data/kinetics_700/videos/cQEe6_mOX58.mp4\n",
      "data/kinetics_700/videos/quRWiEOG2GI.mp4\n",
      "data/kinetics_700/videos/JGmpseRwv-M.mp4\n",
      "data/kinetics_700/videos/-59dBjAyYyE.mp4\n",
      "data/kinetics_700/videos/IhUmcBKO7dk.mp4\n",
      "data/kinetics_700/videos/J6ULTb4xs3A.mp4\n",
      "data/kinetics_700/videos/TqktQaI7qic.mp4\n",
      "data/kinetics_700/videos/jqjKnpZVmIc.mp4\n",
      "data/kinetics_700/videos/zatSd6dtIIY.mp4\n",
      "data/kinetics_700/videos/YNec3X72lws.mp4\n",
      "data/kinetics_700/videos/fGXz6AZUHds.mp4\n",
      "data/kinetics_700/videos/l99GkYltCJk.mp4\n",
      "data/kinetics_700/videos/lvAD-BsLZ5o.mp4\n",
      "data/kinetics_700/videos/iPgTUdZQtZ0.mp4\n",
      "data/kinetics_700/videos/1Wz0zEDoF1A.mp4\n",
      "data/kinetics_700/videos/erS8ar6m3cA.mp4\n",
      "data/kinetics_700/videos/mWQSxjherZY.mp4\n",
      "data/kinetics_700/videos/LNJOwyattUE.mp4\n",
      "data/kinetics_700/videos/DXviXEPU2tI.mp4\n",
      "data/kinetics_700/videos/UxT3V29X-is.mp4\n",
      "data/kinetics_700/videos/f6pgC5YEwIc.mp4\n",
      "data/kinetics_700/videos/E83LPdtdN9c.mp4\n",
      "data/kinetics_700/videos/IVfNGI5_IWg.mp4\n",
      "data/kinetics_700/videos/u2xCi_6apgg.mp4\n",
      "data/kinetics_700/videos/7d5ot3mLA84.mp4\n",
      "data/kinetics_700/videos/780I7yhcMo4.mp4\n",
      "data/kinetics_700/videos/-i8qXrhHOkY.mp4\n",
      "data/kinetics_700/videos/3qfLZ-2_JoU.mp4\n",
      "data/kinetics_700/videos/2puFq2392xU.mp4\n",
      "data/kinetics_700/videos/IczEHV4i_9w.mp4\n",
      "data/kinetics_700/videos/gEG4crRFyl4.mp4\n",
      "data/kinetics_700/videos/ChaVEFrnmx0.mp4\n",
      "data/kinetics_700/videos/jAAjqMLJ214.mp4\n",
      "data/kinetics_700/videos/M58MHF9GpKI.mp4\n",
      "data/kinetics_700/videos/LOECNbkKA4A.mp4\n",
      "data/kinetics_700/videos/eUc2FR-cFwE.mp4\n",
      "data/kinetics_700/videos/xUvD1pm_TUM.mp4\n",
      "data/kinetics_700/videos/ZnDe4aADhbM.mp4\n",
      "data/kinetics_700/videos/qSUo6zX0pWU.mp4\n",
      "data/kinetics_700/videos/fKwoLf-NxZE.mp4\n",
      "data/kinetics_700/videos/hKT7p1LOJeQ.mp4\n",
      "data/kinetics_700/videos/ThZssGhhi84.mp4\n",
      "data/kinetics_700/videos/5X4Br_ktjRY.mp4\n",
      "data/kinetics_700/videos/8QILuOwPyp0.mp4\n",
      "data/kinetics_700/videos/4f43QcdSMuU.mp4\n",
      "data/kinetics_700/videos/3VPG0vl_838.mp4\n",
      "data/kinetics_700/videos/jhZhKXgWSTM.mp4\n",
      "data/kinetics_700/videos/-NYvR9wYuNk.mp4\n",
      "data/kinetics_700/videos/WATxfSLWoZI.mp4\n",
      "data/kinetics_700/videos/HaK5gDH9GwQ.mp4\n",
      "data/kinetics_700/videos/DVl7vEAhzOY.mp4\n",
      "data/kinetics_700/videos/GSVHV8nG7SE.mp4\n",
      "data/kinetics_700/videos/3_WJ3m1DG4w.mp4\n",
      "data/kinetics_700/videos/-lalLEEvhV8.mp4\n",
      "data/kinetics_700/videos/QNRjD4sWrSI.mp4\n",
      "data/kinetics_700/videos/K3svSLdxVQY.mp4\n",
      "data/kinetics_700/videos/AX5T5BpqYDI.mp4\n",
      "data/kinetics_700/videos/L44hfrzPGlA.mp4\n",
      "data/kinetics_700/videos/1CDdTJ3dRYM.mp4\n",
      "data/kinetics_700/videos/mYFBzBztORA.mp4\n",
      "data/kinetics_700/videos/4sAa3NEHgyY.mp4\n",
      "data/kinetics_700/videos/3zblWOox6nk.mp4\n",
      "data/kinetics_700/videos/AgrTovrsxLo.mp4\n",
      "data/kinetics_700/videos/uEx9foDMRIc.mp4\n",
      "data/kinetics_700/videos/sgwM9fzscak.mp4\n",
      "data/kinetics_700/videos/OKkw7Zo-tug.mp4\n",
      "data/kinetics_700/videos/IKp8kacBeVg.mp4\n",
      "data/kinetics_700/videos/1gmDVbxrkWU.mp4\n",
      "data/kinetics_700/videos/VEITXY7Hl8s.mp4\n",
      "data/kinetics_700/videos/2dUO5_eacgc.mp4\n",
      "data/kinetics_700/videos/FUdRa6v7Xqc.mp4\n",
      "data/kinetics_700/videos/UTBweFBTOkM.mp4\n",
      "data/kinetics_700/videos/vBUJ6e6cE6Y.mp4\n",
      "data/kinetics_700/videos/CBZrH_U8rm0.mp4\n",
      "data/kinetics_700/videos/1KKdgM7-cP0.mp4\n",
      "data/kinetics_700/videos/Wp5AxNB1svE.mp4\n",
      "data/kinetics_700/videos/XM7_sHN5sfQ.mp4\n",
      "data/kinetics_700/videos/fL1SHja1mC4.mp4\n",
      "data/kinetics_700/videos/QDMX3WoV3vI.mp4\n",
      "data/kinetics_700/videos/jMfed6tkfZE.mp4\n",
      "data/kinetics_700/videos/p4PEBG5BsI8.mp4\n",
      "data/kinetics_700/videos/m-6JMfKxmy8.mp4\n",
      "data/kinetics_700/videos/Q4U9xVrG6Vg.mp4\n",
      "data/kinetics_700/videos/XwhyWYla0tI.mp4\n",
      "data/kinetics_700/videos/oXW1WtlaXQQ.mp4\n",
      "data/kinetics_700/videos/frq9eNYqKp4.mp4\n",
      "data/kinetics_700/videos/I920Jgx1-DQ.mp4\n",
      "data/kinetics_700/videos/MDKZNdc6hqk.mp4\n",
      "data/kinetics_700/videos/XTzu0zcnyLQ.mp4\n",
      "data/kinetics_700/videos/BOEfDBC8AMQ.mp4\n",
      "data/kinetics_700/videos/SsbWz4zoMJQ.mp4\n",
      "data/kinetics_700/videos/2KeONYo3h6g.mp4\n",
      "data/kinetics_700/videos/cO2CHBw0WVc.mp4\n",
      "data/kinetics_700/videos/obrgB2x9U-Y.mp4\n",
      "data/kinetics_700/videos/UuTs3g4L534.mp4\n",
      "data/kinetics_700/videos/xaHG8E7gvOU.mp4\n",
      "data/kinetics_700/videos/Y0-rguWi3SU.mp4\n",
      "data/kinetics_700/videos/W8R-UPfEYRI.mp4\n",
      "data/kinetics_700/videos/yPsCiU2yDMc.mp4\n",
      "data/kinetics_700/videos/PYmaGWEWexw.mp4\n",
      "data/kinetics_700/videos/cJC3CGX5zus.mp4\n",
      "data/kinetics_700/videos/gD7OsnKGgKU.mp4\n",
      "data/kinetics_700/videos/zcVaHtKvSwo.mp4\n",
      "data/kinetics_700/videos/1BkRWkHCMjQ.mp4\n",
      "data/kinetics_700/videos/gG72pS0Rr_k.mp4\n",
      "data/kinetics_700/videos/1NjhcQ1ehl4.mp4\n",
      "data/kinetics_700/videos/P4WSt5g9mxg.mp4\n",
      "data/kinetics_700/videos/cG6pS7WP-sk.mp4\n",
      "data/kinetics_700/videos/LlGEzEg_FOQ.mp4\n",
      "data/kinetics_700/videos/3TMa_GTZ3no.mp4\n",
      "data/kinetics_700/videos/W3ROrEJpLyA.mp4\n",
      "data/kinetics_700/videos/dtOyun8eJso.mp4\n",
      "data/kinetics_700/videos/uiY_4AYrPLY.mp4\n",
      "data/kinetics_700/videos/rHJa09KcDN0.mp4\n",
      "data/kinetics_700/videos/ak8Q6hpnWW4.mp4\n",
      "data/kinetics_700/videos/fz74PTYKWBU.mp4\n",
      "data/kinetics_700/videos/-XyE05XlEqo.mp4\n",
      "data/kinetics_700/videos/vT5koVSnop4.mp4\n",
      "data/kinetics_700/videos/7yBzc_Y5dUI.mp4\n",
      "data/kinetics_700/videos/RGI-q_zmdAk.mp4\n",
      "data/kinetics_700/videos/TA7Sy-PSTeU.mp4\n",
      "data/kinetics_700/videos/IRVdoeDoUaU.mp4\n",
      "data/kinetics_700/videos/Bj9bjhu_4I8.mp4\n",
      "data/kinetics_700/videos/cBgqOPex1wI.mp4\n",
      "data/kinetics_700/videos/6GHXZks_Iig.mp4\n",
      "data/kinetics_700/videos/S1Ce0nMApWY.mp4\n",
      "data/kinetics_700/videos/MZ70hlIaC1Q.mp4\n",
      "data/kinetics_700/videos/_SyU7s7WUbE.mp4\n",
      "data/kinetics_700/videos/25HoFzbA_8U.mp4\n",
      "data/kinetics_700/videos/8HHao9TM3dA.mp4\n",
      "data/kinetics_700/videos/_usld3qWfTQ.mp4\n",
      "data/kinetics_700/videos/kvm_zlJnvmQ.mp4\n",
      "data/kinetics_700/videos/zkMa6fNKrLk.mp4\n",
      "data/kinetics_700/videos/9BHjKQyFKoo.mp4\n",
      "data/kinetics_700/videos/5NKgOUvI1rI.mp4\n",
      "data/kinetics_700/videos/F65aAbC-PcQ.mp4\n",
      "data/kinetics_700/videos/jeQrvMYFjlY.mp4\n",
      "data/kinetics_700/videos/yM1m2a59oyc.mp4\n",
      "data/kinetics_700/videos/9y2adEG9-BM.mp4\n",
      "data/kinetics_700/videos/3_-uFSyTu2E.mp4\n",
      "data/kinetics_700/videos/vCifsULstmQ.mp4\n",
      "data/kinetics_700/videos/ZPiZ4OCXXr4.mp4\n",
      "data/kinetics_700/videos/5zNpOlB53hc.mp4\n",
      "data/kinetics_700/videos/_i3ZDX4v-5k.mp4\n",
      "data/kinetics_700/videos/ySvP6CsE4L4.mp4\n",
      "data/kinetics_700/videos/xPk8k0xFIF4.mp4\n",
      "data/kinetics_700/videos/a1g973WbUc4.mp4\n",
      "data/kinetics_700/videos/TXrAvffsw4E.mp4\n",
      "data/kinetics_700/videos/sXy7JRlV8T8.mp4\n",
      "data/kinetics_700/videos/XeWvRscoNhw.mp4\n",
      "data/kinetics_700/videos/19mfKnwywu8.mp4\n",
      "data/kinetics_700/videos/H3JrIFt-Z7U.mp4\n",
      "data/kinetics_700/videos/7t9SFobTgUc.mp4\n",
      "data/kinetics_700/videos/Sw33eGUKQ2k.mp4\n",
      "data/kinetics_700/videos/o0Hg2a3zJs4.mp4\n",
      "data/kinetics_700/videos/MrJMf-dV-dY.mp4\n",
      "data/kinetics_700/videos/3anhRKfeN9g.mp4\n",
      "data/kinetics_700/videos/d9h0v4I37Fg.mp4\n",
      "data/kinetics_700/videos/KkatF_rUdMQ.mp4\n",
      "data/kinetics_700/videos/FY4MgGpsXYg.mp4\n",
      "data/kinetics_700/videos/VihiSB8_fdw.mp4\n",
      "data/kinetics_700/videos/ZTACAngMXWY.mp4\n",
      "data/kinetics_700/videos/9y2Hyc-NNwI.mp4\n",
      "data/kinetics_700/videos/hJ2SPDIZH3U.mp4\n",
      "data/kinetics_700/videos/0oMQFAurqK4.mp4\n",
      "data/kinetics_700/videos/uERX4zE4-4U.mp4\n",
      "data/kinetics_700/videos/C9gOhhsZGfM.mp4\n",
      "data/kinetics_700/videos/2nw_8_VOVAU.mp4\n",
      "data/kinetics_700/videos/-m4lDw7atUE.mp4\n",
      "data/kinetics_700/videos/A3waLm5ig50.mp4\n",
      "data/kinetics_700/videos/lFN-7WrfZks.mp4\n",
      "data/kinetics_700/videos/k8LAphfa6j4.mp4\n",
      "data/kinetics_700/videos/a19abgLQxdU.mp4\n",
      "data/kinetics_700/videos/0-v_fA3WPXI.mp4\n",
      "data/kinetics_700/videos/E9czDLqMfn8.mp4\n",
      "data/kinetics_700/videos/RDk268e_H6g.mp4\n",
      "data/kinetics_700/videos/PDOpSD9ZdYE.mp4\n",
      "data/kinetics_700/videos/m1aNSsGM4bQ.mp4\n",
      "data/kinetics_700/videos/Ftcy3zLLAyU.mp4\n",
      "data/kinetics_700/videos/QF99vKY3om8.mp4\n",
      "data/kinetics_700/videos/2YnmRDZ_OK4.mp4\n",
      "data/kinetics_700/videos/0so1jmNGlC4.mp4\n",
      "data/kinetics_700/videos/JszusEtKGlw.mp4\n",
      "data/kinetics_700/videos/7khYEFsH4Pw.mp4\n",
      "data/kinetics_700/videos/IFCOo7JLLJo.mp4\n",
      "data/kinetics_700/videos/hI7bRsvEB28.mp4\n",
      "data/kinetics_700/videos/TGUk7M5plmA.mp4\n",
      "data/kinetics_700/videos/iPmhT2Bkc68.mp4\n",
      "data/kinetics_700/videos/l-3B4T5yENw.mp4\n",
      "data/kinetics_700/videos/0fCZ4MW3jYU.mp4\n",
      "data/kinetics_700/videos/lnfY8F-ygyk.mp4\n",
      "data/kinetics_700/videos/L1RPQcWU-1Y.mp4\n",
      "data/kinetics_700/videos/dwrxsO5Jk4w.mp4\n",
      "data/kinetics_700/videos/48huDLh1H0I.mp4\n",
      "data/kinetics_700/videos/dsPI3gukJLU.mp4\n",
      "data/kinetics_700/videos/ILWv8hGOvyg.mp4\n",
      "data/kinetics_700/videos/-m2WZLslIqw.mp4\n",
      "data/kinetics_700/videos/6uZuqyfL8Ps.mp4\n",
      "data/kinetics_700/videos/1pNdXcMQX_8.mp4\n",
      "data/kinetics_700/videos/JdygbpqRYbE.mp4\n",
      "After: 2426\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\", df.shape[0])\n",
    "for i, row in df.iterrows():\n",
    "    if not os.path.exists(row['video_path']):\n",
    "        print(row['video_path'])\n",
    "        df.drop(i, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"After:\", df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:56.340441100Z",
     "start_time": "2024-04-22T21:44:55.570637500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train, X_val, _, _ = train_test_split(df, df['label'])\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_val.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:56.347997300Z",
     "start_time": "2024-04-22T21:44:56.342444500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "labels = X_train[\"label\"].unique()\n",
    "labels2id = {label:i for i, label in enumerate(labels)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:56.352476400Z",
     "start_time": "2024-04-22T21:44:56.348998500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.5)\n",
    "], additional_targets={\n",
    "    f'image{i}': 'image' for i in range(1, 8)\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:44:56.359595300Z",
     "start_time": "2024-04-22T21:44:56.357075800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "from utils.video_processing import sample_frame_indices, read_video_pyav, apply_video_augmentations\n",
    "\n",
    "\n",
    "class ActionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, meta, transform=None):\n",
    "        self.meta = meta\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                file_path = self.meta['video_path'].iloc[idx]\n",
    "                container = av.open(file_path)\n",
    "\n",
    "                indices = sample_frame_indices(clip_len=8, frame_sample_rate=5, seg_len=container.streams.video[0].frames)\n",
    "                video = read_video_pyav(container, indices)\n",
    "                while video.shape[0] < 8:\n",
    "                    video = np.vstack([video, video[-1:]])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"loop Error: \", e)\n",
    "                continue\n",
    "            break\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = apply_video_augmentations(video, self.transform)\n",
    "            video = transformed\n",
    "\n",
    "        inputs = processor(\n",
    "            text=[self.meta['label'].iloc[idx]],\n",
    "            videos=list(video),\n",
    "            return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            max_length=8\n",
    "        )\n",
    "        for i in inputs:\n",
    "            inputs[i] = inputs[i][0]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def validate_videos(self):\n",
    "        for i, row in self.meta.iterrows():\n",
    "            if not os.path.exists(row['video_path']):\n",
    "                print(row['video_path'])\n",
    "                self.meta.drop(i, inplace=True)\n",
    "                continue\n",
    "\n",
    "            self.__getitem__(i)\n",
    "        self.meta.reset_index(drop=True, inplace=True)\n",
    "        return self.meta"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:08:23.563977100Z",
     "start_time": "2024-04-22T22:08:23.547792800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128, transform=None):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        video = self.load_video(row['video'])\n",
    "        video = self.transform(video)\n",
    "        text = row['text']\n",
    "        text = self.tokenizer(text, max_length=self.max_length, padding='max_length', truncation=True,\n",
    "                              return_tensors='pt')\n",
    "        return video, text['input_ids'].squeeze(), text['attention_mask'].squeeze()\n",
    "\n",
    "    def load_video(self, path):\n",
    "        container = av.open(path)\n",
    "        video = []\n",
    "        for packet in container.demux():\n",
    "            for frame in packet.decode():\n",
    "                image = frame.to_image()\n",
    "                image = np.array(image)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                video.append(image)\n",
    "        video = np.stack(video)\n",
    "        return video"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:08:24.062359200Z",
     "start_time": "2024-04-22T22:08:24.058414700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "train_dataset = ActionDataset(meta=X_train, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=31, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:08:28.412398500Z",
     "start_time": "2024-04-22T22:08:28.403323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "(1819, 7)"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:08:29.211543700Z",
     "start_time": "2024-04-22T22:08:29.203968100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-5\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr) # 289"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:08:30.440382400Z",
     "start_time": "2024-04-22T22:08:30.417394800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch: 0:   0%|          | 0/59 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2954ad704beb46588664d7fe4b9fc6e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n",
      "Unused or unrecognized kwargs: max_length, padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[101], line 12\u001B[0m\n\u001B[0;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     10\u001B[0m batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 12\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[0;32m     15\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\x_clip\\modeling_x_clip.py:1586\u001B[0m, in \u001B[0;36mXCLIPModel.forward\u001B[1;34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1583\u001B[0m img_features \u001B[38;5;241m=\u001B[39m img_features\u001B[38;5;241m.\u001B[39mview(batch_size, num_frames, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, video_embeds\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m   1584\u001B[0m img_features \u001B[38;5;241m=\u001B[39m img_features\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m-> 1586\u001B[0m text_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1587\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1588\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1589\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1590\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1591\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1592\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1593\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1595\u001B[0m text_embeds \u001B[38;5;241m=\u001B[39m text_outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1596\u001B[0m text_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_projection(text_embeds)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\x_clip\\modeling_x_clip.py:764\u001B[0m, in \u001B[0;36mXCLIPTextTransformer.forward\u001B[1;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    761\u001B[0m     \u001B[38;5;66;03m# [batch_size, seq_len] -> [batch_size, 1, tgt_seq_len, src_seq_len]\u001B[39;00m\n\u001B[0;32m    762\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m _prepare_4d_attention_mask(attention_mask, hidden_states\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m--> 764\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    765\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    766\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    767\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    768\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    769\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    771\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    773\u001B[0m last_hidden_state \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    774\u001B[0m last_hidden_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_layer_norm(last_hidden_state)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\x_clip\\modeling_x_clip.py:694\u001B[0m, in \u001B[0;36mXCLIPEncoder.forward\u001B[1;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    686\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    687\u001B[0m         encoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    688\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    691\u001B[0m         output_attentions,\n\u001B[0;32m    692\u001B[0m     )\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 694\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mencoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    699\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    701\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\x_clip\\modeling_x_clip.py:327\u001B[0m, in \u001B[0;36mXCLIPEncoderLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001B[0m\n\u001B[0;32m    324\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[0;32m    326\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm1(hidden_states)\n\u001B[1;32m--> 327\u001B[0m hidden_states, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[0;32m    335\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\x_clip\\modeling_x_clip.py:215\u001B[0m, in \u001B[0;36mXCLIPAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;66;03m# get query proj\u001B[39;00m\n\u001B[0;32m    214\u001B[0m query_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_proj(hidden_states) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale\n\u001B[1;32m--> 215\u001B[0m key_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mk_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, bsz)\n\u001B[0;32m    216\u001B[0m value_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(hidden_states), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, bsz)\n\u001B[0;32m    218\u001B[0m proj_shape \u001B[38;5;241m=\u001B[39m (bsz \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    for i, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch: {epoch}\")):\n",
    "        print(i)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        outputs = model(**batch, return_loss=True)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(i)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    print('Training loss:', np.mean(train_loss))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_targets = []\n",
    "    val_preds = []\n",
    "    for line in tqdm(X_val.itertuples()):\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                file_path = line.video_path\n",
    "                container = av.open(file_path)\n",
    "                indices = sample_frame_indices(clip_len=8, frame_sample_rate=5, seg_len=container.streams.video[0].frames)\n",
    "                video = read_video_pyav(container, indices)\n",
    "                while video.shape[0] < 8:\n",
    "                    video = np.vstack([video, video[-1:]])\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            break\n",
    "\n",
    "        inputs = processor(\n",
    "            text=labels,\n",
    "            videos=list(video),\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "        )\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        logits_per_video = outputs.logits_per_video\n",
    "        probs = logits_per_video.softmax(dim=1)\n",
    "\n",
    "        val_targets.append(line.label_id)\n",
    "        val_preds.append(probs.argmax(axis=1).cpu().numpy()[0])\n",
    "\n",
    "    print('F1:', f1_score(val_targets, val_preds, average='macro'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:14:58.240173300Z",
     "start_time": "2024-04-22T22:08:45.889614500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# empty gpu memory\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
